{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70567216-962a-4b57-b916-dec19eeff210",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e948952-c44f-4191-91f7-547b43e18c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyspark==3.1.1 pyarrow tldextract nltk\n",
    "# !pip install plotly\n",
    "# !pip install chart_studio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aacce4-ac04-45fb-a386-b9a4a69d85da",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b00d4edd-af15-4103-96e3-03d51621fc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYSPARK_PYTHON=/opt/conda/bin/python\n",
      "env: PYSPARK_DRIVER_PYTHON=/opt/conda/bin/python\n",
      "env: JAVA_HOME=/usr/lib/jvm/adoptopenjdk-8-hotspot-amd64/jre\n"
     ]
    }
   ],
   "source": [
    "# Make sure that spark uses the same python distribution to avoid serialization issues due to missing packages\n",
    "%env PYSPARK_PYTHON=/opt/conda/bin/python\n",
    "%env PYSPARK_DRIVER_PYTHON=/opt/conda/bin/python\n",
    "%env JAVA_HOME=/usr/lib/jvm/adoptopenjdk-8-hotspot-amd64/jre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c79611c1-4307-4232-af01-998509944eaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "assert sys.executable == os.environ['PYSPARK_PYTHON'], \\\n",
    "    ('Please make sure that PYSPARK_PYTHON environment variable is set to %s' % sys.executable)\n",
    "assert sys.executable == os.environ['PYSPARK_DRIVER_PYTHON'], \\\n",
    "    ('Please make sure that PYSPARK_DRIVER_PYTHON environment variable is set to %s' % sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09d95d8e-c8f8-4687-930e-25d2b0a70e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to ./data/...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Data handling and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly as pl\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import chart_studio\n",
    "import chart_studio.plotly as py\n",
    "chart_studio.tools.set_credentials_file(username='k_beans', api_key='0HwUP0lWpxz05CY8Jeth')\n",
    "\n",
    "# PySpark\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.types import IntegerType, BooleanType, ArrayType, StringType, DoubleType\n",
    "\n",
    "# Helpers\n",
    "import os\n",
    "import json\n",
    "\n",
    "# External libraries\n",
    "import tldextract\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords', './data/')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21499cf2-4faf-4846-b759-da7a698efa99",
   "metadata": {},
   "source": [
    "## Load Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91174d1a-6dd1-4ebc-98cc-43cc4e67d9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://python-20211212-190223.us-central1-a.c.k-beans-project.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa1bb83bc90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = pyspark.SparkConf().setMaster('local[*]').setAll([\n",
    "    ('spark.driver.memory','16G'),\n",
    "    ('spark.driver.maxResultSize', '16G'),\n",
    "    ('spark.executor.memory', '24G'),\n",
    "    ('spark.sql.execution.arrow.pyspark.enabled', True),\n",
    "    ('spark.sql.execution.arrow.maxRecordsPerBatch', 10000),\n",
    "    ('spark.local.dir', '/tmp')\n",
    "])\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf) \\\n",
    "                            .config('spark.jars.packages', 'com.johnsnowlabs.nlp:spark-nlp_2.12:3.3.2') \\\n",
    "                            .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel('ERROR')\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2eb75a-32c3-4173-835f-2a848222c32e",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83c2610c-f356-4489-a3c7-3fc814e20e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR    = 'data/'\n",
    "QB_DATA_DIR = DATA_DIR + 'quotebank_data/'\n",
    "\n",
    "QB_DATA_JSON_BZ2_PATH = QB_DATA_DIR + 'json/quotes-%s.json.bz2'\n",
    "QB_DATA_PROC_PATH     = QB_DATA_DIR + 'processed/quotes-%s.parquet'\n",
    "QB_DATA_EXTENDED_PATH = QB_DATA_DIR + '/home/bigdata/quotebank_extended.parquet' \n",
    "\n",
    "PROFANITY_PARQUET_PATH        = DATA_DIR + 'profanity_expanded.parquet'\n",
    "PROFANITY_SCORES_PARQUET_PATH = DATA_DIR + 'profanity_scores.parquet'\n",
    "SENTIMENTS_PARQUET_PATH       = DATA_DIR + 'sentiments.parquet'\n",
    "EMPATH_PARQUET_PATH           = DATA_DIR + 'empath_ultimate.parquet'\n",
    "\n",
    "SPK_ATTR_PATH             = DATA_DIR + 'speaker_attributes.parquet'\n",
    "SPK_ATTR_WITH_LABELS_PATH = DATA_DIR + 'speaker_attributes_with_labels.parquet'\n",
    "\n",
    "LABELS_PATH = DATA_DIR + 'wikidata_labels_descriptions_quotebank.csv.bz2'\n",
    "\n",
    "YEARS = ['2015', '2016', '2017', '2018', '2019', '2020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acdfcabe-5533-456d-9c13-5db652ca749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "QB_JSON_SCHEMA = StructType.fromJson(json.loads(\n",
    "    '''{  \"type\": \"struct\", \n",
    "        \"fields\": [\n",
    "            {\"name\": \"date\", \"type\": \"string\", \"nullable\": true, \"metadata\": {}}, \n",
    "            {\"name\": \"numOccurrences\", \"type\": \"long\", \"nullable\": true,\"metadata\": {}}, \n",
    "            {\"name\": \"phase\", \"type\": \"string\", \"nullable\": true, \"metadata\": {}}, \n",
    "            {\"name\": \"probas\", \"type\": {\"type\": \"array\", \"elementType\": {\"type\": \"array\", \"elementType\": \"string\", \n",
    "                \"containsNull\": true}, \"containsNull\": true}, \"nullable\": true, \"metadata\": {}}, \n",
    "            {\"name\": \"qids\", \"type\": {\"type\": \"array\", \"elementType\": \"string\", \"containsNull\": true}, \n",
    "                \"nullable\": true, \"metadata\": {}}, \n",
    "            {\"name\": \"quotation\", \"type\": \"string\", \"nullable\": true, \"metadata\": {}}, \n",
    "            {\"name\": \"quoteID\", \"type\": \"string\", \"nullable\": true, \"metadata\": {}}, \n",
    "            {\"name\": \"speaker\", \"type\": \"string\", \"nullable\": true, \"metadata\": {}}, \n",
    "            {\"name\": \"urls\", \"type\": {\"type\": \"array\", \"elementType\": \"string\", \"containsNull\": true}, \"nullable\": true, \n",
    "                \"metadata\": {}}\n",
    "            ]\n",
    "    }'''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "930ad995-5e2a-4b9f-84f4-8f5525af6c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_list_to_tlds(urls):\n",
    "    try:\n",
    "        if urls is None or len(urls) == 0:\n",
    "            return None\n",
    "        res = list(map(lambda url : tldextract.extract(url).domain, urls))\n",
    "        return res if res else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def fill_columns(iterator):\n",
    "    for df in iterator:\n",
    "        df['speaker_qid']   = df['qids'].apply(lambda qids : None if (qids is None or len(qids) == 0) else qids[0])         \n",
    "        df['speaker_prob']  = df['probas'].apply(lambda p : 0.0 if (p is None or len(p) == 0) else float(p[0][1]))\n",
    "        df['tlds']          = df['urls'].apply(url_list_to_tlds)\n",
    "        yield df\n",
    "        \n",
    "def prepare_data(df):    \n",
    "    df = df.withColumn('speaker_qid', f.lit(None).cast(StringType()))\n",
    "    df = df.withColumn('speaker_prob', f.lit(None).cast(DoubleType()))\n",
    "    df = df.withColumn('tlds', df.urls)\n",
    "    df = df.mapInPandas(fill_columns, schema = df.schema)\n",
    "    return df\n",
    "\n",
    "def prepare_data_for_years(years):\n",
    "    for y in years:\n",
    "        df = spark.read.json(QB_DATA_JSON_BZ2_PATH % y, schema=QB_JSON_SCHEMA)\n",
    "        df = df.withColumnRenamed('numOccurrences', 'occurrences')\n",
    "        df = prepare_data(df)\n",
    "        df.write.parquet(QB_DATA_PROC_PATH % y, 'overwrite')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4154d70-bd63-41a5-85ca-937827cd9b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data_for_years(YEARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "246010bd-acc4-4947-a075-5760a0683199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "qb_all = spark.read.parquet(QB_DATA_PROC_PATH % YEARS[0])\n",
    "for y in YEARS[1:]:\n",
    "    qb_all = qb_all.union(spark.read.parquet(QB_DATA_PROC_PATH % y))\n",
    "    \n",
    "profanity = spark.read.parquet(PROFANITY_PARQUET_PATH)\n",
    "profanity_scores = spark.read.parquet(PROFANITY_SCORES_PARQUET_PATH)\n",
    "empath = spark.read.parquet(EMPATH_PARQUET_PATH)\n",
    "sentiments = spark.read.parquet(SENTIMENTS_PARQUET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "927335eb-64a2-4955-8416-d12ab2961981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+\n",
      "|censored|profanity|    count|\n",
      "+--------+---------+---------+\n",
      "|     0.0|        0|113818503|\n",
      "|     0.0|        1|   780678|\n",
      "|     1.0|        1|   365490|\n",
      "+--------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profanity.groupby('censored', 'profanity').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35ad51b9-5597-4a1e-9914-324622b321b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "empath_ext = empath \\\n",
    "    .withColumn('has_pos_emotion', f.when(f.col('positive_emotion') == 0, 0).otherwise(1)) \\\n",
    "    .withColumn('has_neg_emotion', f.when(f.col('negative_emotion') == 0, 0).otherwise(1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "108ed74c-8fe7-4204-8c74-b7fc77246e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+--------+\n",
      "|has_pos_emotion|has_neg_emotion|   count|\n",
      "+---------------+---------------+--------+\n",
      "|              1|              0|12505906|\n",
      "|              1|              1| 3271197|\n",
      "|              0|              0|89357914|\n",
      "|              0|              1|10449240|\n",
      "+---------------+---------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empath_ext.groupby('has_pos_emotion', 'has_neg_emotion').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7680d6d5-3546-4a02-9b6c-1fd16ea35f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:====================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|sentiment|   count|\n",
      "+---------+--------+\n",
      "|        0|   68959|\n",
      "|        1|50350768|\n",
      "|       -1|64544944|\n",
      "+---------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sentiments.groupby('sentiment').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d449a9e2-69f0-4add-ab05-f3199be4140a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 43:====================================================> (194 + 6) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+---------------+--------+\n",
      "|sentiment|has_pos_emotion|has_neg_emotion|   count|\n",
      "+---------+---------------+---------------+--------+\n",
      "|       -1|              0|              0|50496242|\n",
      "|       -1|              0|              1| 5806235|\n",
      "|       -1|              1|              0| 6547476|\n",
      "|       -1|              1|              1| 1694991|\n",
      "|        0|              0|              0|   64394|\n",
      "|        0|              0|              1|    1985|\n",
      "|        0|              1|              0|    2064|\n",
      "|        0|              1|              1|     516|\n",
      "|        1|              0|              0|38267137|\n",
      "|        1|              0|              1| 4591720|\n",
      "|        1|              1|              0| 5927459|\n",
      "|        1|              1|              1| 1564452|\n",
      "+---------+---------------+---------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sentiments.join(empath_ext, on='quoteID').groupby('sentiment', 'has_pos_emotion', 'has_neg_emotion').count()\\\n",
    "    .sort('sentiment', 'has_pos_emotion', 'has_neg_emotion').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "512f4871-f13a-42f1-8433-bad13fcf4405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:====================================================> (194 + 6) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+---------------+--------+\n",
      "|filtered_sentiment|has_pos_emotion|has_neg_emotion|   count|\n",
      "+------------------+---------------+---------------+--------+\n",
      "|                -1|              0|              0| 4847163|\n",
      "|                -1|              0|              1|  315645|\n",
      "|                -1|              1|              0|  294105|\n",
      "|                -1|              1|              1|   42795|\n",
      "|                 0|              0|              0|81762980|\n",
      "|                 0|              0|              1| 9910340|\n",
      "|                 0|              1|              0|11838230|\n",
      "|                 0|              1|              1| 3156397|\n",
      "|                 1|              0|              0| 2217630|\n",
      "|                 1|              0|              1|  173955|\n",
      "|                 1|              1|              0|  344664|\n",
      "|                 1|              1|              1|   60767|\n",
      "+------------------+---------------+---------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sentiments.withColumn('filtered_sentiment', f.when(f.col('confidence') < 0.6, 0).otherwise(f.col('sentiment'))) \\\n",
    "    .join(empath_ext, on='quoteID').groupby('filtered_sentiment', 'has_pos_emotion', 'has_neg_emotion').count()\\\n",
    "    .sort('filtered_sentiment', 'has_pos_emotion', 'has_neg_emotion').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6bec08e-f4c4-4dfc-b4c6-d5a834d56754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# records in quotebank       115584257\n",
      "# records in empath          115584257\n",
      "# records in profanity       114964671\n",
      "# records in prfanity_scores 114964671\n",
      "# records in sentiments      114964671\n"
     ]
    }
   ],
   "source": [
    "print('# records in quotebank      ', qb_all.count())\n",
    "print('# records in empath         ', empath.count())\n",
    "print('# records in profanity      ', profanity.count())\n",
    "print('# records in prfanity_scores', profanity_scores.count())\n",
    "print('# records in sentiments     ', sentiments.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929ab754-d306-4d9f-a0d2-018a722017a1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1ecc94-e0bb-4e40-9440-85f5dec90f99",
   "metadata": {},
   "source": [
    "#### Extend quotebank data with additional columns and save the intemediate dataframe for faster processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1470232b-9a08-4de1-8ae5-3d5e86c4b8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "qb = qb_all \\\n",
    "        .join(profanity, on='quoteID') \\\n",
    "        .join(profanity_scores \\\n",
    "                  .withColumnRenamed('scores', 'profanity_score') \\\n",
    "                  .select('quoteID', 'profanity_score'), on='quoteID') \\\n",
    "        .join(empath, on='quoteID') \\\n",
    "        .join(sentiments, on='quoteID') \\\n",
    "        .select('quoteID', 'date', 'occurrences', 'quotation', 'speaker', 'speaker_qid', \n",
    "                'speaker_prob', 'tlds', 'profanity', 'profanity_score', 'censored', \n",
    "                'sentiment', 'confidence', 'positive_emotion', 'negative_emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f733aea7-1a91-4399-9259-13f40a8aaa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "qb.write.parquet(QB_DATA_EXTENDED_PATH, 'overwrite')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
