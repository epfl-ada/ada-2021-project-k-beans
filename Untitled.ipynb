{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e1088af-56f7-4b4d-8e53-d4a10df59a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# PySpark\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.types import IntegerType, BooleanType, ArrayType, StringType\n",
    "\n",
    "#Spark NLP\n",
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "\n",
    "# Helpers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bce70914-6d72-4af4-b6c8-9853de652b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://tsf-484-wpa-7-155.epfl.ch:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f848ad83670>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = pyspark.SparkConf().setMaster(\"local[*]\").setAll([\n",
    "    ('spark.driver.memory','16G'),\n",
    "    ('spark.driver.maxResultSize', '8G'),\n",
    "    ('spark.sql.execution.arrow.pyspark.enabled', True),\n",
    "    ('spark.local.dir', '/media/maculjak/2e9080dc-73f3-426f-a054-a46f620aea95/tmp')\n",
    "])\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:3.3.2\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17d7f6f3-ba4e-4987-86ef-9169457363f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data/'\n",
    "QUOTEBANK_DATA_DIR = DATA_DIR + 'quotebank_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87cf3e7-9e9b-49fc-a615-f66658fe0a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for i in os.listdir(QUOTEBANK_DATA_DIR):\n",
    "    dfs.append(spark.read.json(QUOTEBANK_DATA_DIR + i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d05a6c1-4226-442d-a3af-8bce811a375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs[0]\n",
    "for df_part in dfs[1:]:\n",
    "    df = df.union(df_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5edc981-fdb3-425d-bb63-065e8244188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(DATA_DIR + 'qb_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99151ae-feb8-4407-a267-bae48bef99a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = PretrainedPipeline('recognize_entities_dl', lang='en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ea6c0a-684f-46f9-968e-2e3e0be14720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_entities(x, entity):\n",
    "    return any([i.entity == entity for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71640cec-278a-46f5-9cbe-0e25e7724fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipeline.annotate(dff.limit(100), column='quotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cff79347-d92d-446d-a164-b7b4b6fc2665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "def entities_to_str_entity_pair(x):\n",
    "    return [(i.result, i.metadata['entity']) for i in x] #if i.result not in (\"I'd\", \"I'm\", \"He's\", \"She's\", \"I\", \"He'd\", \"She'd\", \"They\", \"They're\", \"You\", \"You're\", \"You'd\", \"He\", \"She\", \"I've\", \"W're\")]\n",
    "df = pipeline.annotate(dff.where(dff.date.rlike('^2020')), column='quotation')\\\n",
    "    .select('quoteID', f.udf(entities_to_str_entity_pair, ArrayType(ArrayType(StringType())))(f.col('entities')).alias('entities'))\n",
    "\n",
    "df.write.parquet('2020-quotes-ner.parquet')\n",
    "# df = df.withColumn('entities', ).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26f2c78c-7c2f-4666-9de2-9f8048c1aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ner = spark.read.parquet('2020-quotes-ner.parquet')\n",
    "# dff.where(f.col('quoteID') == '2020-02-10-003820').first()\n",
    "# def has_person(x):\n",
    "#     return any([i[1] == 'PER' for i in x])\n",
    "# dfff.where(f.udf(has_person, BooleanType())(f.col('entities'))).()\n",
    "def is_person(x):\n",
    "    return x[1] == 'PER'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e707121a-b4f1-4ca5-bd64-bf1807d505f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 118:================================>                        (4 + 3) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|entity     |count|\n",
      "+-----------+-----+\n",
      "|[Dick, PER]|163  |\n",
      "+-----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_ner.select(f.explode(f.col('entities')).alias('entity')).where(f.udf(is_person, BooleanType())(f.col('entity')))\\\n",
    ".groupby('entity').count().sort('count', ascending=False).show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dae748d7-fe43-4ba4-b8a3-3b02164c8898",
   "metadata": {},
   "outputs": [],
   "source": [
    "conspiracy_theorists = set(map(lambda x: x.lower(), pd.read_csv('conspiracy.csv')['itemLabel']))\n",
    "def is_conspiracy_theorist(x):\n",
    "    return str(x) in conspiracy_theorists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40d5d75b-e545-4834-8c25-7a55acbc503d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:====================================================> (296 + 7) / 303]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------+\n",
      "|           speaker| count|\n",
      "+------------------+------+\n",
      "|      Donald Trump|252214|\n",
      "|        Alex Jones|  8586|\n",
      "|        Mike Adams|  3971|\n",
      "|      John Coleman|  3135|\n",
      "|    Robert Spencer|  1670|\n",
      "|      David Berger|  1621|\n",
      "|     Pamela Geller|  1613|\n",
      "|    Mike Cernovich|  1493|\n",
      "|     Bradley Smith|  1464|\n",
      "|      Jerome Corsi|  1324|\n",
      "|     Patrick Moore|  1096|\n",
      "|Paul Joseph Watson|   989|\n",
      "|        Rick Wiles|   958|\n",
      "|         Mark Lane|   816|\n",
      "|      Jack Burkman|   704|\n",
      "|      Craig Murray|   631|\n",
      "|      DONALD Trump|   627|\n",
      "|      DONALD TRUMP|   621|\n",
      "| Daniel Greenfield|   583|\n",
      "|     Kevin Barrett|   528|\n",
      "+------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select('quotation').where(f.lower(f.col('speaker')).isin(conspiracy_theorists)).where().groupby('speaker').count().sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6632a767-2512-4b6d-964c-57a40f4bb803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:============>                                          (70 + 8) / 303]\r"
     ]
    }
   ],
   "source": [
    "df.join(df_ner, on='quoteID').select('quotation', 'entities').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8290b54-71ff-409f-8f3c-c2709d69eb38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
