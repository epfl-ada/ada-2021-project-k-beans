{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e1088af-56f7-4b4d-8e53-d4a10df59a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# PySpark\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.types import IntegerType, BooleanType, ArrayType, StringType, MapType, FloatType\n",
    "\n",
    "#Spark NLP\n",
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "\n",
    "# Helpers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bce70914-6d72-4af4-b6c8-9853de652b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/09 18:44:15 WARN Utils: Your hostname, aventinus resolves to a loopback address: 127.0.1.1; using 192.168.1.118 instead (on interface wlp5s0)\n",
      "21/11/09 18:44:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/maculjak/anaconda3/envs/ada/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/maculjak/anaconda3/envs/ada/lib/python3.8/site-packages/pyspark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/maculjak/.ivy2/cache\n",
      "The jars for the packages stored in: /home/maculjak/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-6d21f5a4-1e7e-4443-83de-f172435cf9de;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;3.3.2 in central\n",
      "\tfound com.typesafe#config;1.4.1 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.5.3 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.603 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.code.findbugs#annotations;3.0.1 in central\n",
      "\tfound net.jcip#jcip-annotations;1.0 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.1 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.21 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound org.json4s#json4s-ext_2.12;3.5.3 in central\n",
      "\tfound joda-time#joda-time;2.9.5 in central\n",
      "\tfound org.joda#joda-convert;1.8.1 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.3.3 in central\n",
      "\tfound net.sf.trove4j#trove4j;3.0.3 in central\n",
      ":: resolution report :: resolve 539ms :: artifacts dl 15ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.603 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.code.findbugs#annotations;3.0.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.1 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;3.3.2 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.3.3 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.1 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tjoda-time#joda-time;2.9.5 from central in [default]\n",
      "\tnet.jcip#jcip-annotations;1.0 from central in [default]\n",
      "\tnet.sf.trove4j#trove4j;3.0.3 from central in [default]\n",
      "\torg.joda#joda-convert;1.8.1 from central in [default]\n",
      "\torg.json4s#json4s-ext_2.12;3.5.3 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.5.3 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.21 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   21  |   0   |   0   |   0   ||   21  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-6d21f5a4-1e7e-4443-83de-f172435cf9de\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 21 already retrieved (0kB/11ms)\n",
      "21/11/09 18:44:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/11/09 18:44:16 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.118:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f848a00ca90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = pyspark.SparkConf().setMaster(\"local[*]\").setAll([\n",
    "    ('spark.driver.memory','16G'),\n",
    "    ('spark.driver.maxResultSize', '8G'),\n",
    "    ('spark.sql.execution.arrow.pyspark.enabled', True),\n",
    "    ('spark.local.dir', '/media/maculjak/2e9080dc-73f3-426f-a054-a46f620aea95/tmp')\n",
    "])\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:3.3.2\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17d7f6f3-ba4e-4987-86ef-9169457363f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data/'\n",
    "QUOTEBANK_DATA_DIR = DATA_DIR + 'quotebank_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87cf3e7-9e9b-49fc-a615-f66658fe0a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for i in os.listdir(QUOTEBANK_DATA_DIR):\n",
    "    dfs.append(spark.read.json(QUOTEBANK_DATA_DIR + i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d05a6c1-4226-442d-a3af-8bce811a375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs[0]\n",
    "for df_part in dfs[1:]:\n",
    "    df = df.union(df_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5edc981-fdb3-425d-bb63-065e8244188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(DATA_DIR + 'qb_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99151ae-feb8-4407-a267-bae48bef99a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = PretrainedPipeline('recognize_entities_dl', lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ea6c0a-684f-46f9-968e-2e3e0be14720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_entities(x, entity):\n",
    "    return any([i.entity == entity for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71640cec-278a-46f5-9cbe-0e25e7724fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipeline.annotate(dff.limit(100), column='quotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cff79347-d92d-446d-a164-b7b4b6fc2665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "def entities_to_str_entity_pair(x):\n",
    "    return [(i.result, i.metadata['entity']) for i in x] #if i.result not in (\"I'd\", \"I'm\", \"He's\", \"She's\", \"I\", \"He'd\", \"She'd\", \"They\", \"They're\", \"You\", \"You're\", \"You'd\", \"He\", \"She\", \"I've\", \"W're\")]\n",
    "df = pipeline.annotate(dff.where(dff.date.rlike('^2020')), column='quotation')\\\n",
    "    .select('quoteID', f.udf(entities_to_str_entity_pair, ArrayType(ArrayType(StringType())))(f.col('entities')).alias('entities'))\n",
    "\n",
    "df.write.parquet('2020-quotes-ner.parquet')\n",
    "# df = df.withColumn('entities', ).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26f2c78c-7c2f-4666-9de2-9f8048c1aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ner = spark.read.parquet('2020-quotes-ner.parquet')\n",
    "# dff.where(f.col('quoteID') == '2020-02-10-003820').first()\n",
    "# def has_person(x):\n",
    "#     return any([i[1] == 'PER' for i in x])\n",
    "# dfff.where(f.udf(has_person, BooleanType())(f.col('entities'))).()\n",
    "def is_person(x):\n",
    "    return x[1] == 'PER'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e707121a-b4f1-4ca5-bd64-bf1807d505f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 118:================================>                        (4 + 3) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|entity     |count|\n",
      "+-----------+-----+\n",
      "|[Dick, PER]|163  |\n",
      "+-----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_ner.select(f.explode(f.col('entities')).alias('entity')).where(f.udf(is_person, BooleanType())(f.col('entity')))\\\n",
    ".groupby('entity').count().sort('count', ascending=False).show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dae748d7-fe43-4ba4-b8a3-3b02164c8898",
   "metadata": {},
   "outputs": [],
   "source": [
    "conspiracy_theorists = set(map(lambda x: x.lower(), pd.read_csv('conspiracy.csv')['itemLabel']))\n",
    "def is_conspiracy_theorist(x):\n",
    "    return str(x) in conspiracy_theorists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40d5d75b-e545-4834-8c25-7a55acbc503d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:====================================================> (296 + 7) / 303]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------+\n",
      "|           speaker| count|\n",
      "+------------------+------+\n",
      "|      Donald Trump|252214|\n",
      "|        Alex Jones|  8586|\n",
      "|        Mike Adams|  3971|\n",
      "|      John Coleman|  3135|\n",
      "|    Robert Spencer|  1670|\n",
      "|      David Berger|  1621|\n",
      "|     Pamela Geller|  1613|\n",
      "|    Mike Cernovich|  1493|\n",
      "|     Bradley Smith|  1464|\n",
      "|      Jerome Corsi|  1324|\n",
      "|     Patrick Moore|  1096|\n",
      "|Paul Joseph Watson|   989|\n",
      "|        Rick Wiles|   958|\n",
      "|         Mark Lane|   816|\n",
      "|      Jack Burkman|   704|\n",
      "|      Craig Murray|   631|\n",
      "|      DONALD Trump|   627|\n",
      "|      DONALD TRUMP|   621|\n",
      "| Daniel Greenfield|   583|\n",
      "|     Kevin Barrett|   528|\n",
      "+------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select('quotation').where(f.lower(f.col('speaker')).isin(conspiracy_theorists)).where().groupby('speaker').count().sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6632a767-2512-4b6d-964c-57a40f4bb803",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.join(df_ner, on='quoteID').select('quotation', 'entities', 'probas').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8290b54-71ff-409f-8f3c-c2709d69eb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "test_quotes = [i.quotation for i in df.sample(0.00001).select('quotation').collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "181aeaf5-8215-42a8-b824-be165f5e9605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1183"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7ef20e8-6960-4bfc-8780-b039cc7cdf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from top2vec import Top2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a803ec4-27f2-4264-9b23-24c2d6e9094d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-07 19:29:12,767 - top2vec - INFO - Pre-processing documents for training\n",
      "2021-11-07 19:29:12,848 - top2vec - INFO - Creating joint document/word embedding\n",
      "2021-11-07 19:29:15,147 - top2vec - INFO - Creating lower dimension embedding of documents\n",
      "2021-11-07 19:29:18,273 - top2vec - INFO - Finding dense areas of documents\n",
      "2021-11-07 19:29:18,311 - top2vec - INFO - Finding topics\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.553746938705444"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "model = Top2Vec(documents=test_quotes)\n",
    "time.time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90bc6aae-d7e9-448e-9bff-af23d6bba0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8ec9d75-e132-49eb-84d7-b6f1555f66f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "75595368"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.where(f.col('speaker') != 'None').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da6036e4-5824-48a7-9fb8-33a308606ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:=====================================================> (193 + 7) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+------+\n",
      "|speaker                   |count |\n",
      "+--------------------------+------+\n",
      "|President Donald Trump    |313624|\n",
      "|Donald Trump              |252214|\n",
      "|Narendra Modi             |147239|\n",
      "|President Trump           |145751|\n",
      "|Pope Francis              |102993|\n",
      "|Hillary Clinton           |95458 |\n",
      "|Bernie Sanders            |84018 |\n",
      "|President Barack Obama    |73149 |\n",
      "|Jose Mourinho             |65029 |\n",
      "|Rodrigo Duterte           |60906 |\n",
      "|Jurgen Klopp              |59651 |\n",
      "|Benjamin Netanyahu        |58734 |\n",
      "|Joe Biden                 |57891 |\n",
      "|Vladimir Putin            |55895 |\n",
      "|President Obama           |52870 |\n",
      "|Rahul Gandhi              |52854 |\n",
      "|Nancy Pelosi              |51999 |\n",
      "|Boris Johnson             |49713 |\n",
      "|Jeremy Corbyn             |48512 |\n",
      "|Elizabeth Warren          |48397 |\n",
      "|Mike Pence                |46893 |\n",
      "|Pep Guardiola             |46313 |\n",
      "|Ted Cruz                  |46301 |\n",
      "|Lindsey Graham            |45069 |\n",
      "|Andrew Cuomo              |45049 |\n",
      "|Justin Trudeau            |44821 |\n",
      "|Mike Pompeo               |44155 |\n",
      "|Elon Musk                 |43601 |\n",
      "|Arun Jaitley              |42143 |\n",
      "|Marco Rubio               |41626 |\n",
      "|Mitch McConnell           |40532 |\n",
      "|Theresa May               |39871 |\n",
      "|Scott Morrison            |38350 |\n",
      "|LeBron James              |38312 |\n",
      "|Amit Shah                 |37697 |\n",
      "|Imran Khan                |36884 |\n",
      "|Paul Ryan                 |36375 |\n",
      "|Steve Kerr                |36265 |\n",
      "|Joe Maddon                |34585 |\n",
      "|Bill de Blasio            |34512 |\n",
      "|Lewis Hamilton            |34263 |\n",
      "|Malcolm Turnbull          |33699 |\n",
      "|Chuck Schumer             |33668 |\n",
      "|Muhammadu Buhari          |33652 |\n",
      "|Virat Kohli               |33525 |\n",
      "|Mark Zuckerberg           |32861 |\n",
      "|Stephen Colbert           |32443 |\n",
      "|Pete Carroll              |32342 |\n",
      "|Tom Brady                 |32107 |\n",
      "|John McCain               |30997 |\n",
      "|Emmanuel Macron           |30863 |\n",
      "|Mauricio Pochettino       |30727 |\n",
      "|Angela Merkel             |30680 |\n",
      "|Jeff Sessions             |30478 |\n",
      "|Kim Kardashian            |30431 |\n",
      "|Bill Belichick            |30298 |\n",
      "|Mamata Banerjee           |30220 |\n",
      "|Arvind Kejriwal           |29078 |\n",
      "|Tiger Woods               |28062 |\n",
      "|Chris Christie            |28041 |\n",
      "|John Kerry                |27842 |\n",
      "|Rand Paul                 |27511 |\n",
      "|Recep Tayyip Erdogan      |27345 |\n",
      "|Adam Schiff               |27009 |\n",
      "|David Cameron             |26938 |\n",
      "|Barack Obama              |26866 |\n",
      "|Tim Cook                  |26596 |\n",
      "|Jimmy Kimmel              |25973 |\n",
      "|Antonio Conte             |25637 |\n",
      "|Taylor Swift              |25576 |\n",
      "|James Comey               |25570 |\n",
      "|Mahathir Mohamad          |25189 |\n",
      "|Roger Federer             |24987 |\n",
      "|Kanye West                |24923 |\n",
      "|Serena Williams           |24719 |\n",
      "|Joe Girardi               |24591 |\n",
      "|Brendan Rodgers           |24577 |\n",
      "|Jim Cramer                |24542 |\n",
      "|Nikki Haley               |24508 |\n",
      "|Nick Saban                |24505 |\n",
      "|Pete Buttigieg            |24487 |\n",
      "|Doug Pederson             |24407 |\n",
      "|Terry Francona            |24236 |\n",
      "|Brad Stevens              |24197 |\n",
      "|Prime Minister Theresa May|24176 |\n",
      "|Dana White                |23926 |\n",
      "|John Farrell              |23834 |\n",
      "|Xi Jinping                |23745 |\n",
      "|Jeb Bush                  |23407 |\n",
      "|Jacinda Ardern            |23399 |\n",
      "|Kellyanne Conway          |23033 |\n",
      "|Rex Tillerson             |22932 |\n",
      "|Scott Walker              |22890 |\n",
      "|Leo Varadkar              |22854 |\n",
      "|Salvador Panelo           |22826 |\n",
      "|Nicola Sturgeon           |22671 |\n",
      "|Sean Spicer               |22506 |\n",
      "|Steve Smith               |22481 |\n",
      "|Meghan Markle             |22427 |\n",
      "|Ben Carson                |22382 |\n",
      "+--------------------------+------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.where(f.col('speaker') != 'None').groupby('speaker').count().sort('count', ascending=False).show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5fc818b-9397-4c4d-acad-7060ff3390ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed: Cannot train from DataFrame without POS annotatorType by posCol",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35457/1040138401.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m ])\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mpipelineModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/site-packages/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mindexOfLastEstimator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \"\"\"\n\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: Cannot train from DataFrame without POS annotatorType by posCol"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.training import *\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"quotation\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "wordSegmenter = WordSegmenterApproach() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"token\") \\\n",
    "    .setPosColumn(\"tags\") \\\n",
    "    .setNIterations(5)\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    documentAssembler,\n",
    "    wordSegmenter\n",
    "])\n",
    "\n",
    "pipelineModel = pipeline.fit(df.sample(0.00001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e2b0b89-9640-4132-82f2-a5fcc4bce8d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Params must be either a param map or a list/tuple of param maps, but got <class 'str'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35457/3911810430.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"em\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'quotation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ada/lib/python3.8/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n\u001b[0m\u001b[1;32m    164\u001b[0m                              \"but got %s.\" % type(params))\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Params must be either a param map or a list/tuple of param maps, but got <class 'str'>."
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors, SparseVector\n",
    "from pyspark.ml.clustering import LDA\n",
    "\n",
    "lda = LDA(k=20, seed=1, optimizer=\"em\")\n",
    "model = lda.fit(df.sample(0.00001).with, 'quotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f385fa1-43b0-45c6-909c-af3fcb6b6c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "818225"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('speaker').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41504605-72f9-4dfe-91d5-4bf78af8398a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:==============================================>       (174 + 8) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(count)|\n",
      "+----------+\n",
      "|  40800538|\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select('speaker').groupby('speaker').count().where(f.col('count') < 1000).agg(f.sum('count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "088dae3b-8b2d-4c48-9288-56159384944a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n",
      "\u001b[K     |████████████████████████████████| 235 kB 5.2 MB/s eta 0:00:01\n",
      "\u001b[33mWARNING: Error parsing requirements for numpy: [Errno 2] No such file or directory: '/home/maculjak/anaconda3/envs/ada/lib/python3.8/site-packages/numpy-1.20.3.dist-info/METADATA'\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: unidecode\n",
      "Successfully installed unidecode-1.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54614e67-c0e5-403d-814d-a8e6d363811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e13ef8a-2796-40a3-bdb0-5d9f690de6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Trump's\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('quotation').where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b102517a-a1d6-448b-acc3-bb605052de67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "counts = df.select('speaker', 'qids').groupby('speaker', 'qids').count().sort('count', asc=False).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "28216b89-84f8-40df-802e-6a81780fd508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56891/1842366420.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d['qids'] = d['qids'].apply(lambda x: 'Q' + str(min(map(lambda y: int(y[1:]), x))))\n"
     ]
    }
   ],
   "source": [
    "d = counts[counts['speaker'] != 'None']\n",
    "d['qids'] = d['qids'].apply(lambda x: 'Q' + str(min(map(lambda y: int(y[1:]), x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5eaebec5-ff07-436f-b74a-d6a577829b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qids</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q1000053</th>\n",
       "      <td>943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q1000074</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q1000087</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q1000204</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q1000275</th>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q999769</th>\n",
       "      <td>1535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q999795</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q999889</th>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q999968</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q999975</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>703288 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          count\n",
       "qids           \n",
       "Q1000053    943\n",
       "Q1000074      2\n",
       "Q1000087      8\n",
       "Q1000204     36\n",
       "Q1000275    118\n",
       "...         ...\n",
       "Q999769    1535\n",
       "Q999795      17\n",
       "Q999889     120\n",
       "Q999968      23\n",
       "Q999975       1\n",
       "\n",
       "[703288 rows x 1 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.sort_values('count', ascending=False).groupby('qids').sum('count').sort_values(')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3593986f-b9d8-41e8-812b-1db86baa493c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230242</th>\n",
       "      <td>( SANDY ) ALEX G</td>\n",
       "      <td>Q20709155</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741178</th>\n",
       "      <td>( Sandy ) Alex G</td>\n",
       "      <td>Q20709155</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55148</th>\n",
       "      <td>... LANGE</td>\n",
       "      <td>Q55088840</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592590</th>\n",
       "      <td>... Lane</td>\n",
       "      <td>Q55088819</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276326</th>\n",
       "      <td>... Lange</td>\n",
       "      <td>Q55088840</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135921</th>\n",
       "      <td>Šárka Pančochová</td>\n",
       "      <td>Q2483405</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32800</th>\n",
       "      <td>ŽELJKO KRAJAN</td>\n",
       "      <td>Q8083655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25533</th>\n",
       "      <td>Želimir Žilnik</td>\n",
       "      <td>Q1264297</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179372</th>\n",
       "      <td>Željko Ivanek</td>\n",
       "      <td>Q382197</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125774</th>\n",
       "      <td>Željko Krajan</td>\n",
       "      <td>Q8083655</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200361 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 speaker       qids  count\n",
       "230242  ( SANDY ) ALEX G  Q20709155      3\n",
       "741178  ( Sandy ) Alex G  Q20709155    170\n",
       "55148          ... LANGE  Q55088840      1\n",
       "592590          ... Lane  Q55088819     33\n",
       "276326         ... Lange  Q55088840      4\n",
       "...                  ...        ...    ...\n",
       "135921  Šárka Pančochová   Q2483405      2\n",
       "32800      ŽELJKO KRAJAN   Q8083655      1\n",
       "25533     Želimir Žilnik   Q1264297      1\n",
       "179372     Željko Ivanek    Q382197      2\n",
       "125774     Željko Krajan   Q8083655      2\n",
       "\n",
       "[200361 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[d.duplicated('qids', keep=False)].sort_values('speaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c29b29da-2cff-476b-a6a4-b8cffdfacf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts['lens'] = counts['qids'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c82df504-1774-4f80-861a-657cc330daef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56891/853796196.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  counts[counts.lens > 1][counts['count'] > 10000]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>count</th>\n",
       "      <th>lens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>817816</th>\n",
       "      <td>John Roberts</td>\n",
       "      <td>[Q11153, Q14949621, Q16196671, Q19325651, Q208...</td>\n",
       "      <td>10030</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817819</th>\n",
       "      <td>Doug Ford</td>\n",
       "      <td>[Q28066064, Q4348031, Q5300478, Q5300480]</td>\n",
       "      <td>10073</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817830</th>\n",
       "      <td>Mark Hughes</td>\n",
       "      <td>[Q1494363, Q214513, Q21516094, Q3294110, Q3367...</td>\n",
       "      <td>10312</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817834</th>\n",
       "      <td>John Williams</td>\n",
       "      <td>[Q11310708, Q12633687, Q131285, Q1367551, Q149...</td>\n",
       "      <td>10365</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817836</th>\n",
       "      <td>Winston Peters</td>\n",
       "      <td>[Q1396178, Q5625319]</td>\n",
       "      <td>10409</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818188</th>\n",
       "      <td>Imran Khan</td>\n",
       "      <td>[Q155164, Q15987686, Q1660487, Q17306146, Q183...</td>\n",
       "      <td>36884</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818189</th>\n",
       "      <td>Amit Shah</td>\n",
       "      <td>[Q19946588, Q4746875, Q4746876]</td>\n",
       "      <td>37697</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818191</th>\n",
       "      <td>Scott Morrison</td>\n",
       "      <td>[Q1286476, Q21285393, Q7436904, Q7436906, Q743...</td>\n",
       "      <td>38350</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818192</th>\n",
       "      <td>Theresa May</td>\n",
       "      <td>[Q264766, Q30161835]</td>\n",
       "      <td>39871</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818222</th>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>[Q22686, Q27947481]</td>\n",
       "      <td>252214</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               speaker                                               qids  \\\n",
       "817816    John Roberts  [Q11153, Q14949621, Q16196671, Q19325651, Q208...   \n",
       "817819       Doug Ford          [Q28066064, Q4348031, Q5300478, Q5300480]   \n",
       "817830     Mark Hughes  [Q1494363, Q214513, Q21516094, Q3294110, Q3367...   \n",
       "817834   John Williams  [Q11310708, Q12633687, Q131285, Q1367551, Q149...   \n",
       "817836  Winston Peters                               [Q1396178, Q5625319]   \n",
       "...                ...                                                ...   \n",
       "818188      Imran Khan  [Q155164, Q15987686, Q1660487, Q17306146, Q183...   \n",
       "818189       Amit Shah                    [Q19946588, Q4746875, Q4746876]   \n",
       "818191  Scott Morrison  [Q1286476, Q21285393, Q7436904, Q7436906, Q743...   \n",
       "818192     Theresa May                               [Q264766, Q30161835]   \n",
       "818222    Donald Trump                                [Q22686, Q27947481]   \n",
       "\n",
       "         count  lens  \n",
       "817816   10030    22  \n",
       "817819   10073     4  \n",
       "817830   10312    14  \n",
       "817834   10365    51  \n",
       "817836   10409     2  \n",
       "...        ...   ...  \n",
       "818188   36884    25  \n",
       "818189   37697     3  \n",
       "818191   38350     5  \n",
       "818192   39871     2  \n",
       "818222  252214     2  \n",
       "\n",
       "[98 rows x 4 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts[counts.lens > 1][counts['count'] > 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "93f86e9b-e6f1-4ee9-a985-532415398f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "410"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers = set(counts[(counts['count'] > 10000) & (counts['speaker'] != 'None')].speaker)\n",
    "len(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "946799e2-c4df-4f59-9f6b-ee018b7f5b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.05025625228882\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "m = 0\n",
    "for i in speakers:\n",
    "    for j in speakers:\n",
    "        m += len(i) + len(j)\n",
    "print(time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "089023c0-26b3-4fef-bed3-097b726a1e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8513416"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts[counts.speaker.isin(speakers)]['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e2516883-5eda-4967-9417-299b9ac35e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1b59169e-20cc-4ce7-b6cc-8d6f3ef18102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[251.41750425, 186.09194996, 188.45788462, ..., 187.97165664,\n",
       "        191.33677433, 188.98229849],\n",
       "       [186.09194996, 254.53951633, 187.83945308, ..., 186.46105363,\n",
       "        189.36162003, 193.76817544],\n",
       "       [188.45788462, 187.83945308, 256.02979783, ..., 182.79819681,\n",
       "        192.79039054, 192.10726027],\n",
       "       ...,\n",
       "       [187.97165664, 186.46105363, 182.79819681, ..., 246.14677797,\n",
       "        186.66657753, 189.5945456 ],\n",
       "       [191.33677433, 189.36162003, 192.79039054, ..., 186.66657753,\n",
       "        260.40973149, 200.96562751],\n",
       "       [188.98229849, 193.76817544, 192.10726027, ..., 189.5945456 ,\n",
       "        200.96562751, 266.66173144]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs = np.random.random((1500, 4 * 768))\n",
    "np.linalg.norm(vecs @ vecs.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0e7d8e-21d0-493a-b5b0-f0f43d13f7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0348dbb1-10a8-4057-9809-9c20a807b203",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0180dac-8dab-456f-b49d-a881988cca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc6b9845-a0af-4af8-9e95-1900dbae2d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from profanity_check import predict_prob\n",
    "@f.pandas_udf('float')\n",
    "def get_profanity(x):\n",
    "    return float(predict_prob([x])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f68aa9c-afb2-42c0-8e2e-9f83b686b904",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('profanity', f.udf(get_profanity, FloatType())(f.col('quotation')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5773972d-28bb-44ba-bbd5-6f261346fb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(f.col('profanity') > 0.5).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59f08a17-762d-4fef-92d2-dbf9427faf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: alt-profanity-check 1.0.1\n",
      "Uninstalling alt-profanity-check-1.0.1:\n",
      "  Successfully uninstalled alt-profanity-check-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall alt-profanity-check -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1905e139-6a24-4296-852e-e9f352ceed47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting alt-profanity-check\n",
      "  Using cached alt_profanity_check-1.0.1-py3-none-any.whl\n",
      "Requirement already satisfied: scikit-learn==1.0.1 in /home/maculjak/anaconda3/envs/ada/lib/python3.8/site-packages (from alt-profanity-check) (1.0.1)\n",
      "Requirement already satisfied: joblib>=1.1.0 in /home/maculjak/anaconda3/envs/ada/lib/python3.8/site-packages (from alt-profanity-check) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/maculjak/anaconda3/envs/ada/lib/python3.8/site-packages (from scikit-learn==1.0.1->alt-profanity-check) (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /home/maculjak/anaconda3/envs/ada/lib/python3.8/site-packages (from scikit-learn==1.0.1->alt-profanity-check) (1.21.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/maculjak/anaconda3/envs/ada/lib/python3.8/site-packages (from scikit-learn==1.0.1->alt-profanity-check) (3.0.0)\n",
      "Installing collected packages: alt-profanity-check\n",
      "Successfully installed alt-profanity-check-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install alt-profanity-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85a9ed0c-2118-4f61-b415-7d2354fad0e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bz2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20330/975998251.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/quotebank_data/quotes-2020.json.bz2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0md_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# loading a sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bz2' is not defined"
     ]
    }
   ],
   "source": [
    "with bz2.open('data/quotebank_data/quotes-2020.json.bz2', 'rb') as s_file:\n",
    "    with bz2.open(path_to_out, 'wb') as d_file:\n",
    "        for instance in s_file:\n",
    "            instance = json.loads(instance)\n",
    "            print(instance)# loading a sample\n",
    "            urls = instance['urls'] # extracting list of links\n",
    "            domains = []\n",
    "            instance['domains'] = domains # updating the sample with domain name\n",
    "            d_file.write((json.dumps(instance)+'\\n').encode('utf-8')) # writing in the new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c8f3bdc-2b66-42b4-a6fe-255e3d142cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/maculjak/ada-2021-project-k-beans\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca74223f-1b29-411c-b9f5-63fafc176003",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['dalfskj asldk jadlsk jadslk jadskf jasdj fadskjf hadskhf asdljf asldjf dalskfj adkslfj adskflj dafsl kjdaf lkjaf lasjdf daskfl jadsf'] * 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0592e3a1-4c40-4221-8f06-61ceb0465128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.358476638793945"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "# for i in a:\n",
    "#     predict_prob([i])\n",
    "p = predict_prob(a)\n",
    "time.time() - t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebe64863-408f-412f-b57a-9272c5e51b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_2019 = df.select('quoteID', 'quotation').where(f.col('date').rlike('^2019')).where(f.col('speaker') != 'None').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f8e1a59-2705-47fd-877b-5dab11239d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231.47203707695007"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "df_2019['profanity'] = predict_prob(df_2019['quotation'])\n",
    "time.time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1b67c7ae-b840-4c07-9511-9606718735e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168.27794075012207"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getsizeof(df_2020)/8/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c34ee38b-d0ad-4403-8fa7-77ef7b2b8a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import getsizeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "37b6c36a-4e2d-4923-8561-b8d1462d0087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94435019])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_prob(['coward'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "76f4343d-4aa2-487d-b184-ac9809d3e572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Marathon Man for idiots.',\n",
       " \"And years ago when we made `Clerks,' I remember sitting on set while we were shooting the movie going like, `Man, wouldn't it be cool if Jay and Silent Bob became like Cheech and Chong and they had their own movies? Nah, that's f -- ing stupid.' I live in that stupid f -- ing dream, man, because that dopey kid took a shot.\",\n",
       " 'Words to which objection has been taken by the Speaker over the years include blackguard, coward, git, guttersnipe, hooligan, rat, swine, stoolpigeon and traitor,',\n",
       " 'You absolute thick, privileged, uncaring twat.',\n",
       " 'Vanessa Hudgens, you absolute thick, privileged, uncaring twat,']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in df_2019[df_2019['profanity'] > 0.9].sort_values('profanity')['quotation'][:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3915f1d-117f-4722-820f-64381eb8382d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quoteID      164568\n",
       "quotation    164568\n",
       "profanity    164568\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2019[df_2019['profanity'] > 0.5].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c4dbcfe-f52b-4281-9086-c596858774bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quoteID      14183294\n",
       "quotation    14183294\n",
       "profanity    14183294\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2019.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb963f2-0520-49c1-a455-8f725fcfb7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
